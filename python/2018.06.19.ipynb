{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# DataFrame对象\n",
    "data = {\n",
    "    'color':['blue','green','yellow','red','white'],\n",
    "    'object':['ball', 'pen', 'pencil', 'paper', 'mug'],\n",
    "    'price':[1.2, 1.0, 0.6, 0.9, 1.7]}\n",
    "frame = pd.DataFrame(data)\n",
    "print(frame)\n",
    "\n",
    "print(\"=============================================\")\n",
    "# 新增序列\n",
    "ser = pd.Series(np.arange(5))\n",
    "frame['new'] = ser\n",
    "print(frame)\n",
    "\n",
    "print(\"=============================================\")\n",
    "# 元素的所属关系\n",
    "print(frame.isin([1.0, 'pen']))\n",
    "\n",
    "print(frame[frame.isin([1.0, 'pen'])])\n",
    "\n",
    "print(\"=============================================\")\n",
    "# 删除一列\n",
    "del frame['new']\n",
    "print(frame)\n",
    "\n",
    "print(\"=============================================\")\n",
    "# 筛选\n",
    "print(frame[frame < 1.2])\n",
    "\n",
    "print(\"=============================================\")\n",
    "# 用嵌套字典生成DataFrame对象\n",
    "dict_nest = {\n",
    "    'red': {2012:22, 2018:33},\n",
    "    'white': {2011:13, 2012:22, 2013:16},\n",
    "    'blue': {2011:17, 2012:27, 2013:18}\n",
    "}\n",
    "\n",
    "frame2 = pd.DataFrame(dict_nest)\n",
    "print(frame2)\n",
    "\n",
    "print(\"=============================================\")\n",
    "# DataFrame转置(列变为行，行变为列)\n",
    "frame2.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series([5,0,3,8,4], index=['red','blue','yellow','white','green'])\n",
    "ser.index\n",
    "\n",
    "# Index对象的方法, 返回索引值最小和最大的元素\n",
    "ser.idxmin()\n",
    "ser.idxmax()\n",
    "\n",
    "# 含有重复标签的Index(同样适用于存在重复项的DataFrame, 其返回结果为DataFrame对象)\n",
    "serd = pd.Series(range(6), index=['white', 'white', 'red','blue','yellow','green'])\n",
    "serd\n",
    "serd['white']\n",
    "\n",
    "serd.index.is_unique # False\n",
    "frame.index.is_unique # True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更换索引\n",
    "ser = pd.Series([2,5,7,4], index=['one', 'two', 'three', 'four'])\n",
    "ser\n",
    "\n",
    "# 更换索引\n",
    "ser.reindex(['three', 'four', 'five', 'one'])\n",
    "\n",
    "# 自动填充或插值方法\n",
    "ser3 = pd.Series([1,5,6,3], index=[0,3,5,6])\n",
    "ser3\n",
    "\n",
    "# 使用reindex()函数，method选项的值为ffill，还需要指定索引值的范围\n",
    "# 新插入的索引项目，为前面索引编号比它小的那个一项的元素\n",
    "ser3.reindex(range(6), method='ffill')\n",
    "\n",
    "# DataFrame对象\n",
    "data = {\n",
    "    'color':['blue','green','yellow','red','white'],\n",
    "    'object':['ball', 'pen', 'pencil', 'paper', 'mug'],\n",
    "    'price':[1.2, 1.0, 0.6, 0.9, 1.7]}\n",
    "frame = pd.DataFrame(data)\n",
    "frame.reindex(range(5), method='ffill', columns=['colors', 'price', 'new', 'object'])\n",
    "\n",
    "# 删除\n",
    "ser = pd.Series(np.arange(4), index=['red', 'blue', 'yellow', 'white'])\n",
    "ser\n",
    "ser.drop('yellow') # 删除标签为yellow这一项\n",
    "ser.drop(['blue', 'white'])\n",
    "\n",
    "# 删除DataFrame中的元素,需要指定元素两个轴的轴标签\n",
    "frame\n",
    "# frame.drop([0, 1]) # 删除行\n",
    "frame.drop(['color', 'object'], axis=1) # 删除列\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 算术和数据对齐\n",
    "s1 = pd.Series([3,2,5,1], ['white', 'yellow', 'green', 'blue'])\n",
    "s2 = pd.Series([1,4,7,2,1], ['white', 'yellow','black', 'blue', 'brown'])\n",
    "s1+s2\n",
    "\n",
    "# 同理对DataFrame对象\n",
    "frame1 = pd.DataFrame(np.arange(16).reshape((4,4)),\n",
    "                     index=['red', 'blue', 'yellow', 'white'],\n",
    "                     columns=['ball', 'pen', 'pencil', 'paper'])\n",
    "\n",
    "frame2 = pd.DataFrame(np.arange(12).reshape((4,3)),\n",
    "                     index=['blue', 'green', 'white', 'yellow'],\n",
    "                     columns=['mug', 'pen', 'ball'])\n",
    "frame1+frame2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据结构之间的运算\n",
    "# add(), sub(), div(), mul()\n",
    "frame1.add(frame2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame和Series对象之间的运算\n",
    "frame = pd.DataFrame(np.arange(16).reshape((4,4)),\n",
    "                     index=['red', 'blue', 'yellow', 'white'],\n",
    "                     columns=['ball', 'pen', 'pencil', 'paper'])\n",
    "print(frame)\n",
    "print(\"==================================================\")\n",
    "ser = pd.Series(np.arange(4), index=['ball', 'pen', 'pencil', 'paper'])\n",
    "print(ser)\n",
    "\n",
    "frame-ser # 为每一行减去ser\n",
    "\n",
    "# 如果一个索引项只存在于其中一个数据结构之中\n",
    "# 则运算结果中会为该索引项生成一列\n",
    "# 只不过该列的所有元素都是NaN\n",
    "ser['mug'] = 9\n",
    "ser\n",
    "frame-ser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas库以NumPy为基础，并对很多功能进行扩展\n",
    "# 新数据结构Series和DataFrame\n",
    "# 通用函数ufunc，就是经过扩展得到的\n",
    "frame = pd.DataFrame(np.arange(16).reshape((4,4)),\n",
    "                     index=['red', 'blue', 'yellow', 'white'],\n",
    "                     columns=['ball', 'pen', 'pencil', 'paper'])\n",
    "print(frame)\n",
    "print(\"==================================================\")\n",
    "ret = np.sqrt(frame) # 对每个元素的平方根\n",
    "print(ret)\n",
    "\n",
    "# 按行或列执行操作的函数\n",
    "# 第一种形式\n",
    "f = lambda x: x.max() - x.min() \n",
    "#第二种形式\n",
    "def f(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "ret = frame.apply(f) # 使用apply函数可以在DataFrame对象上调用刚定义的函数\n",
    "print(ret)\n",
    "\n",
    "# 处理行\n",
    "print(frame.apply(f, axis=1))\n",
    "\n",
    "# apply()函数并不一定返回标量，还可以返回Series对象\n",
    "# 可以借助它同时执行多个函数，返回两个或两个以上的结果\n",
    "def f(x):\n",
    "    return pd.Series([x.min(), x.max()], index=['min', 'max'])\n",
    "\n",
    "frame.apply(f)\n",
    "\n",
    "# 统计函数\n",
    "# 数组的大多数统计函数对DataFrame对象依旧有效，因此没有必要使用apply()函数\n",
    "# 比如， sum(),mean()\n",
    "frame.sum()\n",
    "frame.mean()\n",
    "frame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 排序和排位次\n",
    "ser = pd.Series([5,0,3,8,4], index=['red', 'blue', 'yellow', 'white', 'green'])\n",
    "ser.sort_index() # 字母升序\n",
    "ser.sort_index(ascending=False) # 字母降序\n",
    "\n",
    "# 对于DataFrame对象，可以分别对两条轴中的任意一条进行排序\n",
    "# 对行进行排序，依旧使用sort_index()函数\n",
    "# 对于列需要执行axis选项，其值为1\n",
    "frame = pd.DataFrame(np.arange(16).reshape((4,4)),\n",
    "                     index=['red', 'blue', 'yellow', 'white'],\n",
    "                     columns=['ball', 'pen', 'pencil', 'paper'])\n",
    "print(frame)\n",
    "print(\"==================================================\")\n",
    "print(frame.sort_index()) # 对行进行排序\n",
    "print(\"==================================================\")\n",
    "print(frame.sort_index(axis=1)) # 对列进行排序\n",
    "\n",
    "# 对数据结构中的原序进行排序\n",
    "# 对于Serires对象，使用order()函数\n",
    "# print(ser.order())\n",
    "\n",
    "# frame.sort_values(by='pen')\n",
    "frame.sort_values(by=['pen', 'pencil'])\n",
    "\n",
    "# 排位次操作（ranking）\n",
    "ser.rank()\n",
    "ser.rank(method='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相关性和协方差\n",
    "# 相关性(correlation)和协方差(covariance)\n",
    "# 分别使用函数corr()和cov()\n",
    "seq2 = pd.Series([3,4,3,4,5,4,3,2], ['2006','2007','2008','2009','2010','2011','2012','2013'])\n",
    "seq = pd.Series([1,2,3,4,4,3,2,1], ['2006','2007','2008','2009','2010','2011','2012','2013'])\n",
    "\n",
    "seq.corr(seq2)\n",
    "seq.cov(seq2)\n",
    "\n",
    "# 计算单个DataFrame对象的相关性和协方差，返回两个新DataFrame对象形式的举证\n",
    "frame2 = pd.DataFrame([[1,4,3,6],[4,5,6,1],[3,3,1,5],[4,1,6,4]],\n",
    "                     index=['red', 'blue', 'yellow', 'white'],\n",
    "                     columns=['ball', 'pen', 'pencil', 'paper'])\n",
    "frame2.corr()\n",
    "frame2.cov()\n",
    "\n",
    "# 使用corrwith()方法计算DataFrame对象的列或行\n",
    "# 与Series对象或其他DataFrame对象元素两两之间的相关性\n",
    "ser\n",
    "frame2.corrwith(ser)\n",
    "frame2.corrwith(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN数据\n",
    "# 为元素赋NaN值\n",
    "ser = pd.Series([0,1,2,np.NaN, 9], index=['red', 'blue', 'yellow', 'white', 'green'])\n",
    "ser\n",
    "ser['red'] = None\n",
    "ser\n",
    "\n",
    "# 过滤NaN\n",
    "# 方法一\n",
    "ser.dropna()\n",
    "print(ser.dropna())\n",
    "\n",
    "# 方法二\n",
    "ser[ser.notnull()]\n",
    "\n",
    "# 对于DataFrame处理，使用dropna()方法，只要一行或列有一个NaN元素\n",
    "# 该行或列的全部元素都会被删除\n",
    "frame3 = pd.DataFrame([[6, np.NaN, 6],[np.nan, np.nan, np.nan],[2,np.nan, 5]],\n",
    "                      index = ['blue', 'green', 'red'],\n",
    "                      columns = ['ball', 'mug', 'pen'])\n",
    "print(frame3)\n",
    "frame3.dropna() # 不对\n",
    "\n",
    "# 为了避免删除整行或整列，需要使用how选项，指定其值为all，\n",
    "# 告诉dropna()函数只删除所有元素均为NaN的行或列\n",
    "frame3.dropna(how='all')\n",
    "frame3.dropna(how='all', axis=1)\n",
    "\n",
    "\n",
    "# 为NaN元素填充其他值\n",
    "frame3.fillna(0)\n",
    "\n",
    "frame3.fillna({'ball':1, 'mug': 0, 'pen': 99}) # 指定列名称以及要替换成的元素\n",
    "\n",
    "# 等级索引和分级\n",
    "mser = pd.Series(np.random.rand(8),\n",
    "                index=[['white', 'white', 'white', 'blue', 'blue', 'red', 'red', 'red'],\n",
    "                      ['up','down','right','up','down','up','down','left']])\n",
    "print(mser)\n",
    "print(mser['white'])\n",
    "print(mser[:,'up'])\n",
    "\n",
    "print(mser['white', 'up']) # 选取某一特定的元素，指定两个索引即可\n",
    "\n",
    "mser.unstack() # 转换为一个简单的DataFrame对象，其中把第二列索引转换为相应的列\n",
    "\n",
    "type(frame)\n",
    "frame\n",
    "frame.stack() # 转换为Series对象\n",
    "\n",
    "# 对于DataFrame对象，可以为它的行和列都定义等级索引\n",
    "mframe = pd.DataFrame(np.random.randn(16).reshape(4,4),\n",
    "                     index=[['white','white','red','red'],['up','down','up','down']],\n",
    "                     columns=[['pen','pen','paper','paper'],[1,2,1,2]])\n",
    "mframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新调整顺序和为层级排序\n",
    "# 调整某一条轴上各层级的顺序或调整某一层中各元素的顺序\n",
    "mframe.columns.names = ['object', 'id']\n",
    "mframe.index.names = ['colors','status']\n",
    "mframe\n",
    "mframe.swaplevel('colors','status') # 交换位置\n",
    "import sys\n",
    "mframe.sort_index(level='colors', ascending=True) # 排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按层级统计数据\n",
    "# DataFrame或Series对象的很多描述性和概括统计量都有level选项\n",
    "# 可以指定获取哪个层级的描述心和概括统计量\n",
    "mframe.sum(level='colors')\n",
    "\n",
    "mframe.sum(level='id', axis=1) # 对某一个层级的列进行统计，比如id，需要把axis选项设置为1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取csv文件\n",
    "# 没有表头，使用header选项，将其值置为None,pandas会为其添加默认表头\n",
    "data = pd.read_csv('数据分析/res/worldcup_team_csv.csv', header=None) \n",
    "# 可以指定表头\n",
    "data = pd.read_csv('数据分析/res/worldcup_team_csv.csv', names=['white','red','blue','green','animal']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data.columns))\n",
    "for col in data.columns:\n",
    "    print(col)\n",
    "#     series = data[col]\n",
    "#     print(series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.to_datetime('2010/11/12', format='%Y/%m/%d')\n",
    "print(t)\n",
    "from datetime import datetime\n",
    "dates = [datetime(2012, 5, 1), datetime(2012, 5, 2), datetime(2012, 5, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(np.arange(100),index=pd.timedelta_range('1 days', periods=100, freq='h'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "data = {'birth': ['10/8/00', '7/21/93', '6/14/01', '5/18/99', '1/5/98']}\n",
    "frame = DataFrame(data)\n",
    "\n",
    "frame['birth'] = pd.to_datetime(frame['birth'])\n",
    "frame\n",
    "\n",
    "import datetime as dt\n",
    "now_year =dt.datetime.today().year  #当前的年份\n",
    "frame['age']=now_year-frame.birth.dt.year\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读写HTML文件\n",
    "# read_html(), to_html()\n",
    "# html5lib模块: pip install html5lib\n",
    "\n",
    "frame = pd.DataFrame(np.arange(4).reshape(2,2))\n",
    "print(frame.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(np.random.random((4,4)),\n",
    "                    index=['white','black', 'red','blue'],\n",
    "                    columns=['up','down','right','left'])\n",
    "s = ['<HTML>']\n",
    "s.append('<HEAD><TITLE>My DataFrame</TITLE></HEAD>')\n",
    "s.append('<body>')\n",
    "s.append(frame.to_html())\n",
    "s.append('</body></html>')\n",
    "html = ''.join(s)\n",
    "\n",
    "# 写入html文件\n",
    "html_file = open('myframe.html', 'w')\n",
    "html_file.write(html)\n",
    "html_file.close()\n",
    "\n",
    "\n",
    "# 读取html文件\n",
    "web_frames = pd.read_html('myframe.html')\n",
    "web_frames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从xml读取数据\n",
    "# 引入库\n",
    "from lxml import objectify\n",
    "xml = objectify.parse('some.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取Excel文件\n",
    "# to_excel(), read_excel()\n",
    "data1 = pd.read_excel('数据分析/res/data.xls', 'Sheet 1') \n",
    "data2 = pd.read_excel('数据分析/res/data.xls', 'Sheet 2') \n",
    "\n",
    "# 将DataFrame转换为Excel\n",
    "frame = pd.DataFrame(np.random.random((4,4)),\n",
    "                    index=['exp1', 'exp2', 'exp3', 'exp4'],\n",
    "                    columns=['Jan2015', 'Fab2015','Mar2015','Apr2015'])\n",
    "frame.to_excel('数据分析/res/data2.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# JSON数据\n",
    "# read_json(), to_json()\n",
    "frame = pd.DataFrame(np.random.random((4,4)),\n",
    "                    index=['white','black', 'red','blue'],\n",
    "                    columns=['up','down','right','left'])\n",
    "print(frame)\n",
    "frame.to_json('数据分析/res/frame.json')\n",
    "pd.read_json('数据分析/res/frame.json')\n",
    "\n",
    "# 有时候需要规范化(normalization)\n",
    "# 使用pandas库的json_normalize()函数，将字典或列表转换为表格\n",
    "from pandas.io.json import json_normalize\n",
    "file = open('数据分析/res/books.json', 'r')\n",
    "text = file.read()\n",
    "print(text)\n",
    "text = json.loads(text)\n",
    "json_normalize(text, 'books') # 把books作为键的元素的值，该函数使用一串递增的数字作为索引\n",
    "json_normalize(text, 'books', ['writer', 'nationality']) # 增加books同一级的其他键值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDF5格式, 二进制格式\n",
    "# HDF代表等级数据格式(hierarchical data format), 由c语言开发\n",
    "# HDF5格式数据的方法：PyTables和h5py\n",
    "# h5py为HDF5的高级API提供接口，PyTables封装了很多HDF5细节\n",
    "# HDFStroe, 类似dict类，用PyTables存储pandas对象\n",
    "from pandas.io.pytables import HDFStore\n",
    "frame = pd.DataFrame(np.random.random((4,4)),\n",
    "                    index=['white','black', 'red','blue'],\n",
    "                    columns=['up','down','right','left'])\n",
    "store = pd.HDFStore('数据分析/res/mydata2.h5')\n",
    "store['obj1'] = frame\n",
    "store['obj2'] = frame\n",
    "print(store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle python对象序列化\n",
    "import pickle as pk  \n",
    "data = {'color':['white', 'red'], 'value':[5,7]}\n",
    "pickled_data = pk.dumps(data)\n",
    "print(pk.loads(pickled_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用pandas实现对象序列化\n",
    "frame = pd.DataFrame(np.arange(16).reshape(4,4), index=['up','down','left','right'])\n",
    "frame.to_pickle('数据分析/res/frame.pkl')\n",
    "\n",
    "ret = pd.read_pickle('数据分析/res/frame.pkl')\n",
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 内置SQLite3数据读写\n",
    "from sqlalchemy import create_engine\n",
    "frame = pd.DataFrame(np.arange(20).reshape(4,5),\n",
    "                    columns=['white','red','blue','black','green'])\n",
    "engine = create_engine('sqlite:///数据分析/res/foo.db')\n",
    "# frame.to_sql('colors', engine) # 保存数据库\n",
    "\n",
    "pd.read_sql('colors', engine) # 读取数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x11aa9a420>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "query = \"\"\"CREATE TABLE test (a VARCHAR(20), b VARCHAR(20), c REAL, d INTEGER);\"\"\"\n",
    "con = sqlite3.connect(':memory:')\n",
    "con.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x11a378650>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [('white', 'up', 1, 3),\n",
    "       ('black', 'down', 2, 8),\n",
    "       ('green', 'up', 4, 4),\n",
    "       ('red','down', 5,5)]\n",
    "stmt = \"INSERT INTO test VALUES(?,?,?,?)\"\n",
    "con.executemany(stmt, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>white</td>\n",
       "      <td>up</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>black</td>\n",
       "      <td>down</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>green</td>\n",
       "      <td>up</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>red</td>\n",
       "      <td>down</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       a     b    c  d\n",
       "0  white    up  1.0  3\n",
       "1  black  down  2.0  8\n",
       "2  green    up  4.0  4\n",
       "3    red  down  5.0  5"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor = con.execute('select * from test')\n",
    "cursor\n",
    "rows = cursor.fetchall()\n",
    "rows\n",
    "# 可以把元组列表传给DataFrame的构造函数，如需要列名称，\n",
    "# 可以用游标的description属性来获取\n",
    "cursor.description\n",
    "\"\"\"\n",
    "因为 python 3.x 需要 list()后，再索引查找元素 \n",
    "改为 DataFrame(rows, columns=list(zip(*cursor.description))[0])  \n",
    "\"\"\"\n",
    "pd.DataFrame(rows, columns=list(zip(*cursor.description))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用pgAdmin\n",
    "import psycopg2\n",
    "engine = create_engine('postgresql://postgres:password@localhost:54749/postgres')\n",
    "frame = pd.DataFrame(np.random.random((4,4)),\n",
    "                    index=['exp1','exp2','exp3','exp4'],\n",
    "                    columns=['fed','mar','apr','may'])\n",
    "frame.to_sql('dataframe', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      2\n",
       "3      3\n",
       "4      4\n",
       "5      5\n",
       "6      6\n",
       "7      7\n",
       "8      8\n",
       "9      9\n",
       "10    10\n",
       "11    11\n",
       "12    12\n",
       "13    13\n",
       "14    14\n",
       "15    15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
